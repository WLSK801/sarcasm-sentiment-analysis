{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__      = 'Yu Cao'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "from string import punctuation as Punct\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCorpus(corpus_path):\n",
    "    df = pd.read_csv(corpus_path)\n",
    "    df = df.fillna('')\n",
    "    df['count'] = pd.Series(\n",
    "        [ rawToCount(x) for x in df['pairs_diff'] ], \n",
    "        index = df.index\n",
    "    )\n",
    "    return shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isPunct(s):\n",
    "    return s in Punct or s in [\"``\", \"''\"]\n",
    "\n",
    "def rawToCount(pairs_diff):\n",
    "    pairs_diff = pairs_diff.replace('@', '')\n",
    "    tripleList = pairs_diff.split('\\t')\n",
    "    if len(tripleList) < 3: return None\n",
    "\n",
    "    count = {}\n",
    "    for triple in tripleList[:-1]:\n",
    "        triple = triple.split(',')\n",
    "        if len(triple) != 3 or isPunct(triple[0]) or isPunct(triple[1]): continue\n",
    "        \n",
    "        key = '_'.join(triple[:2])\n",
    "        if (not key in count) or (count[key] < float(triple[2])):\n",
    "            count[key] = float(triple[2])\n",
    "        \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabBuild(countList, freqThreshold=20):\n",
    "    vocab = collections.Counter()\n",
    "    for item in countList: \n",
    "        if item is not None:\n",
    "            vocab.update(item.keys())\n",
    "\n",
    "    vocab = vocab.most_common()\n",
    "    for c, item in enumerate(vocab):\n",
    "        if item[1] < freqThreshold: break\n",
    "    \n",
    "    return [ x[0] for x in vocab[:c] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(vocab, df):\n",
    "    def process(count):\n",
    "        if count is None: return None\n",
    "        vector = np.empty(lenVocab)\n",
    "        vector.fill(-1.)\n",
    "        for key in count.keys(): \n",
    "            if key in vocab:\n",
    "                 vector[vocab.index(key)] = count[key]\n",
    "        \n",
    "        return vector\n",
    "\n",
    "    lenVocab = len(vocab)\n",
    "    df['vector'] = pd.Series(\n",
    "        [ process(x) for x in df['count'] ],\n",
    "        index=df.index\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNone(vectorDF, labelDF):\n",
    "    tlist = [(v, l) for (v, l) in zip(vectorDF, labelDF) \n",
    "    if v is not None]\n",
    "    return [v for (v, l) in tlist], [l for (v, l) in tlist]\n",
    "\n",
    "def getBowVectorizer(df, smallerDim=100):\n",
    "    vectorizer = CountVectorizer()\n",
    "    dimReducer = PCA(n_components=smallerDim)\n",
    "    _, corpus = removeNone(df['vector'], df['text'])\n",
    "    vectorizer.fit(corpus)\n",
    "    dimReducer.fit(vectorizer.transform(corpus).toarray())\n",
    "    return vectorizer, dimReducer\n",
    "\n",
    "def getDimReducer(df, smallerDim=100):\n",
    "    dimReducer = PCA(n_components=smallerDim)\n",
    "    X, _ = removeNone(df['vector'], df['label'])\n",
    "    return dimReducer.fit(X)\n",
    "\n",
    "def bowToArray(df, bowVectorizer, dimReducer):\n",
    "    _, corpus = removeNone(df['vector'], df['text'])\n",
    "    X_bow = bowVectorizer.transform(corpus)\n",
    "    if dimReducer is not None:\n",
    "        return dimReducer.transform(X_bow.toarray())\n",
    "    else:\n",
    "        return X_bow.toarray()\n",
    "\n",
    "def getPredictorTarget(df, bowVectorizer=None, dimReducer=None):\n",
    "    if bowVectorizer is None:\n",
    "        X, y = removeNone(df['vector'], df['label'])\n",
    "        if dimReducer is not None:\n",
    "            X = dimReducer.transform(X)\n",
    "    else:\n",
    "        X = bowToArray(df, bowVectorizer, dimReducer)\n",
    "        _, y = removeNone(df['vector'], df['label'])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelTrain(df, bowVectorizer=None, dimReducer=None):\n",
    "    modelList = [\n",
    "        GaussianNB(),\n",
    "        SVC(),\n",
    "        DecisionTreeClassifier(),\n",
    "        RandomForestClassifier()\n",
    "    ]\n",
    "    X, y = getPredictorTarget(df, bowVectorizer, dimReducer)\n",
    "    for model in modelList:\n",
    "        model.fit(X, y)\n",
    "    return modelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalModels(df, modelList, bowVectorizer=None, dimReducer=None):\n",
    "    X, y = getPredictorTarget(df, bowVectorizer, dimReducer)\n",
    "    for model in modelList:\n",
    "        y_pred = model.predict(X)\n",
    "        print(\n",
    "            '\\n*** %s ***\\n' % str(model)[:str(model).find('(')],\n",
    "            'Prec ' + str(precision_score(y, y_pred)),\n",
    "            'Reca ' + str(recall_score(y, y_pred)),\n",
    "            'F1 ' + str(f1_score(y, y_pred)),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** GaussianNB ***\n",
      " Prec 0.5315656565656566 Reca 0.7581032412965186 F1 0.6249381494309749\n",
      "\n",
      "*** SVC ***\n",
      " Prec 0.6138461538461538 Reca 0.4789915966386555 F1 0.5380984490896831\n",
      "\n",
      "*** DecisionTreeClassifier ***\n",
      " Prec 0.5482695810564663 Reca 0.542016806722689 F1 0.5451252641110775\n",
      "\n",
      "*** RandomForestClassifier ***\n",
      " Prec 0.5601131541725601 Reca 0.47539015606242496 F1 0.5142857142857143\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "main\n",
    "'''\n",
    "trainSet = loadCorpus('train.csv')\n",
    "testSet = loadCorpus('test.csv')\n",
    "vocab = vocabBuild(trainSet['count'])\n",
    "\n",
    "embed(vocab, trainSet)\n",
    "embed(vocab, testSet)\n",
    "modelList = modelTrain(trainSet, dimReducer=None)\n",
    "evalModels(testSet, modelList, dimReducer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** GaussianNB ***\n",
      " Prec 0.5784708249496981 Reca 0.34513805522208885 F1 0.4323308270676691\n",
      "\n",
      "*** SVC ***\n",
      " Prec 0.5946488294314382 Reca 0.5336134453781513 F1 0.5624802277760202\n",
      "\n",
      "*** DecisionTreeClassifier ***\n",
      " Prec 0.5214541120381406 Reca 0.5252100840336135 F1 0.5233253588516746\n",
      "\n",
      "*** RandomForestClassifier ***\n",
      " Prec 0.5652173913043478 Reca 0.4447779111644658 F1 0.4978165938864629\n"
     ]
    }
   ],
   "source": [
    "dim_reducer = getDimReducer(trainSet)\n",
    "modelList = modelTrain(trainSet, bowVectorizer=None, dimReducer=dim_reducer)\n",
    "evalModels(testSet, modelList, bowVectorizer=None, dimReducer=dim_reducer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** GaussianNB ***\n",
      " Prec 0.5592689295039165 Reca 0.6428571428571429 F1 0.5981569394024016\n",
      "\n",
      "*** SVC ***\n",
      " Prec 0.6736474694589878 Reca 0.46338535414165666 F1 0.5490753911806544\n",
      "\n",
      "*** DecisionTreeClassifier ***\n",
      " Prec 0.5532811559301626 Reca 0.5516206482593037 F1 0.5524496543432522\n",
      "\n",
      "*** RandomForestClassifier ***\n",
      " Prec 0.5823442136498517 Reca 0.47118847539015607 F1 0.5209024552090246\n"
     ]
    }
   ],
   "source": [
    "bowVectorizer, dimReducer = getBowVectorizer(trainSet)\n",
    "modelList = modelTrain(trainSet, bowVectorizer, dimReducer)\n",
    "evalModels(testSet, modelList, bowVectorizer, dimReducer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
