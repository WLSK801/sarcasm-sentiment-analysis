{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__      = 'Yu Cao'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "from string import punctuation as Punct\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCorpus(corpus_path):\n",
    "    df = pd.read_csv(corpus_path)\n",
    "    df = df.fillna('')\n",
    "    df['count'] = pd.Series(\n",
    "        [ rawToCount(x) for x in df['pairs_diff'] ], \n",
    "        index = df.index\n",
    "    )\n",
    "    return shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isPunct(s):\n",
    "    return s in Punct or s in [\"``\", \"''\"]\n",
    "\n",
    "def rawToCount(pairs_diff):\n",
    "    pairs_diff = pairs_diff.replace('@', '')\n",
    "    tripleList = [x.split(',') for x in pairs_diff.split('\\t')]\n",
    "    tripleList = [x for x in tripleList\n",
    "        if len(x) == 3 and not isPunct(x[0]) and not isPunct(x[1])\n",
    "    ]\n",
    "    if len(tripleList) < 3: return None\n",
    "\n",
    "    count = {}\n",
    "    for triple in tripleList[:-1]:\n",
    "        key = '_'.join(triple[:2])\n",
    "        if (not key in count) or (count[key] < float(triple[2])):\n",
    "            count[key] = float(triple[2])\n",
    "        \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabBuild(countList, freqThreshold=20):\n",
    "    vocab = collections.Counter()\n",
    "    for item in countList: \n",
    "        if item is not None:\n",
    "            vocab.update(item.keys())\n",
    "\n",
    "    vocab = vocab.most_common()\n",
    "    for c, item in enumerate(vocab):\n",
    "        if item[1] < freqThreshold: break\n",
    "    \n",
    "    return [ x[0] for x in vocab[:c] ]\n",
    "\n",
    "def embed(vocab, df):\n",
    "    def process(count):\n",
    "        if count is None: return None\n",
    "        vector = np.empty(lenVocab)\n",
    "        vector.fill(-1.)\n",
    "        for key in count.keys(): \n",
    "            if key in vocab:\n",
    "                 vector[vocab.index(key)] = count[key]\n",
    "        \n",
    "        return vector\n",
    "\n",
    "    lenVocab = len(vocab)\n",
    "    df['vector'] = pd.Series(\n",
    "        [ process(x) for x in df['count'] ],\n",
    "        index=df.index\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNone(vectorDF, labelDF):\n",
    "    tlist = [(v, l) for (v, l) in zip(vectorDF, labelDF) \n",
    "        if v is not None\n",
    "    ]\n",
    "    return [v for (v, l) in tlist], [l for (v, l) in tlist]\n",
    "\n",
    "def getBowVectorizer(df, smallerDim=100):\n",
    "    vectorizer = CountVectorizer()\n",
    "    dimReducer = PCA(n_components=smallerDim)\n",
    "    _, corpus = removeNone(df['vector'], df['text'])\n",
    "    vectorizer.fit(corpus)\n",
    "    dimReducer.fit(vectorizer.transform(corpus).toarray())\n",
    "    return vectorizer, dimReducer\n",
    "\n",
    "def getDimReducer(df, smallerDim=100):\n",
    "    dimReducer = PCA(n_components=smallerDim)\n",
    "    X, _ = removeNone(df['vector'], df['label'])\n",
    "    return dimReducer.fit(X)\n",
    "\n",
    "def bowToArray(df, bowVectorizer, dimReducer):\n",
    "    _, corpus = removeNone(df['vector'], df['text'])\n",
    "    X_bow = bowVectorizer.transform(corpus)\n",
    "    if dimReducer is not None:\n",
    "        return dimReducer.transform(X_bow.toarray())\n",
    "    else:\n",
    "        return X_bow.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictorTarget(df, bowVectorizer=None, dimReducer=None):\n",
    "    if bowVectorizer is None:\n",
    "        X, y = removeNone(df['vector'], df['label'])\n",
    "        if dimReducer is not None:\n",
    "            X = dimReducer.transform(X)\n",
    "    else:\n",
    "        X = bowToArray(df, bowVectorizer, dimReducer)\n",
    "        _, y = removeNone(df['vector'], df['label'])\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def modelTrain(df, bowVectorizer=None, dimReducer=None):\n",
    "    modelList = [\n",
    "        GaussianNB(),\n",
    "        SVC(),\n",
    "        DecisionTreeClassifier(),\n",
    "        RandomForestClassifier()\n",
    "    ]\n",
    "    X, y = getPredictorTarget(df, bowVectorizer, dimReducer)\n",
    "    for model in modelList:\n",
    "        model.fit(X, y)\n",
    "    return modelList\n",
    "\n",
    "def evalModels(df, modelList, bowVectorizer=None, dimReducer=None):\n",
    "    X, y = getPredictorTarget(df, bowVectorizer, dimReducer)\n",
    "    for model in modelList:\n",
    "        y_pred = model.predict(X)\n",
    "        print(\n",
    "            '\\n*** %s ***\\n' % str(model)[:str(model).find('(')],\n",
    "            'Prec ' + str(precision_score(y, y_pred)),\n",
    "            'Reca ' + str(recall_score(y, y_pred)),\n",
    "            'F1 ' + str(f1_score(y, y_pred)),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "main\n",
    "'''\n",
    "trainSet = loadCorpus('train.csv')\n",
    "testSet = loadCorpus('test.csv')\n",
    "\n",
    "vocab = vocabBuild(trainSet['count'])\n",
    "embed(vocab, trainSet)\n",
    "embed(vocab, testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** GaussianNB ***\n",
      " Prec 0.5297202797202797 Reca 0.7739463601532567 F1 0.628956927867151\n",
      "\n",
      "*** SVC ***\n",
      " Prec 0.6125984251968504 Reca 0.49680715197956576 F1 0.5486600846262342\n",
      "\n",
      "*** DecisionTreeClassifier ***\n",
      " Prec 0.545281823939202 Reca 0.5498084291187739 F1 0.5475357710651829\n",
      "\n",
      "*** RandomForestClassifier ***\n",
      " Prec 0.5702875399361023 Reca 0.4559386973180077 F1 0.5067423704755146\n"
     ]
    }
   ],
   "source": [
    "modelList = modelTrain(trainSet, dimReducer=None)\n",
    "evalModels(testSet, modelList, dimReducer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** GaussianNB ***\n",
      " Prec 0.5941295546558705 Reca 0.37484035759897827 F1 0.45967110415035234\n",
      "\n",
      "*** SVC ***\n",
      " Prec 0.6011355571327183 Reca 0.5408684546615581 F1 0.5694117647058824\n",
      "\n",
      "*** DecisionTreeClassifier ***\n",
      " Prec 0.5276541640178004 Reca 0.5300127713920817 F1 0.5288308378464478\n",
      "\n",
      "*** RandomForestClassifier ***\n",
      " Prec 0.5507358636715725 Reca 0.4540229885057471 F1 0.49772488624431216\n"
     ]
    }
   ],
   "source": [
    "dim_reducer = getDimReducer(trainSet)\n",
    "modelList = modelTrain(trainSet, bowVectorizer=None, dimReducer=dim_reducer)\n",
    "evalModels(testSet, modelList, bowVectorizer=None, dimReducer=dim_reducer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** GaussianNB ***\n",
      " Prec 0.5593582887700534 Reca 0.6679438058748404 F1 0.6088474970896391\n",
      "\n",
      "*** SVC ***\n",
      " Prec 0.6605868358445678 Reca 0.5319284802043422 F1 0.5893172974885037\n",
      "\n",
      "*** DecisionTreeClassifier ***\n",
      " Prec 0.5489949748743719 Reca 0.558109833971903 F1 0.5535148828372387\n",
      "\n",
      "*** RandomForestClassifier ***\n",
      " Prec 0.5808936825885979 Reca 0.48148148148148145 F1 0.526536312849162\n"
     ]
    }
   ],
   "source": [
    "bowVectorizer, dimReducer = getBowVectorizer(trainSet)\n",
    "modelList = modelTrain(trainSet, bowVectorizer, dimReducer)\n",
    "evalModels(testSet, modelList, bowVectorizer, dimReducer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
